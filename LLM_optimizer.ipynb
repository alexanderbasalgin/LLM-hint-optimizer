{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd707fa5-6f34-4d3d-a76b-ef09304c877d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:11:22.880490Z",
     "iopub.status.busy": "2025-10-24T12:11:22.879197Z",
     "iopub.status.idle": "2025-10-24T12:11:22.894497Z",
     "shell.execute_reply": "2025-10-24T12:11:22.893590Z",
     "shell.execute_reply.started": "2025-10-24T12:11:22.880444Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from peft import LoraConfig\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', message='MatMul8bitLt.*')\n",
    "warnings.filterwarnings('ignore', message='.*use_reentrant.*')\n",
    "warnings.filterwarnings('ignore', message='.*torch.utils.checkpoint.*')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc18a06e-387f-445b-bd5c-2450a5fa102d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:11:24.189814Z",
     "iopub.status.busy": "2025-10-24T12:11:24.188653Z",
     "iopub.status.idle": "2025-10-24T12:11:24.212286Z",
     "shell.execute_reply": "2025-10-24T12:11:24.211449Z",
     "shell.execute_reply.started": "2025-10-24T12:11:24.189769Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert PostgreSQL query optimizer specialized in generating pg_hint_plan commands. Your task is to analyze SQL queries along with their database statistics and generate optimal hint commands to improve query execution plans.\n",
    "\n",
    "pg_hint_plan hints include:\n",
    "- Scan method hints: SeqScan, IndexScan, BitmapScan, TidScan\n",
    "- Join method hints: NestLoop, HashJoin, MergeJoin\n",
    "- Join order hints: Leading(...)\n",
    "- Row number correction hints: Rows(...)\n",
    "Generate hints that will result in the most efficient execution plan based on the provided statistics.\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"Analyze the following PostgreSQL query and generate optimal pg_hint_plan commands.\n",
    "\n",
    "**Query:**\n",
    "{query}\n",
    "**Table Cardinalities:**\n",
    "{card_tb}\n",
    "\n",
    "**Column Statistics (NDV):**\n",
    "{ndv}\n",
    "\n",
    "**Most Frequent Values:**\n",
    "{main_value}\n",
    "\n",
    "**Value Ranges (Min/Max):**\n",
    "{min_max}\n",
    "Generate the optimal pg_hint_plan hints for this query.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e92c8c-0b3b-4b49-b2dd-2c3828dbdcae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:11:25.990873Z",
     "iopub.status.busy": "2025-10-24T12:11:25.989731Z",
     "iopub.status.idle": "2025-10-24T12:11:26.006281Z",
     "shell.execute_reply": "2025-10-24T12:11:26.005447Z",
     "shell.execute_reply.started": "2025-10-24T12:11:25.990834Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_ndv_stats(ndv_string):\n",
    "    lines = ndv_string.strip().split('\\n')\n",
    "    formatted = [f\"  - {x.replace(' : ', ': ')}\" for x in lines if ' : ' in x]\n",
    "    return '\\n'.join(formatted)\n",
    "\n",
    "def format_main_values(main_value_string):\n",
    "    lines = main_value_string.strip().split('\\n')\n",
    "    formatted = [f\"  - {x.replace(' : ', ': ')}\" for x in lines if ' : ' in x]\n",
    "    return '\\n'.join(formatted)\n",
    "\n",
    "def format_min_max(min_max_string):\n",
    "    lines = min_max_string.strip().split('\\n')\n",
    "    formatted = [f\"  - {x.replace(' : ', ': ')}\" for x in lines if ' : ' in x]\n",
    "    return '\\n'.join(formatted)\n",
    "\n",
    "def format_training_data(entry):\n",
    "    user_prompt = USER_PROMPT_TEMPLATE.format(\n",
    "        query=entry['query'],\n",
    "        card_tb=entry['Card_Tb'],\n",
    "        ndv=format_ndv_stats(entry['NDV']),\n",
    "        main_value=format_main_values(entry['Main_Value']),\n",
    "        min_max=format_min_max(entry['Min_Max'])\n",
    "    )\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT.strip()},\n",
    "            {\"role\": \"user\", \"content\": user_prompt.strip()},\n",
    "            {\"role\": \"assistant\", \"content\": entry['best_hints'].strip()}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def prepare_training_dataset(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        raw_data = json.load(f)\n",
    "    formatted_data = [format_training_data(e) for e in raw_data]\n",
    "    dataset = Dataset.from_list(formatted_data)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff91678-d4ed-44e1-8fb6-8111cc0df3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:11:30.607640Z",
     "iopub.status.busy": "2025-10-24T12:11:30.606481Z",
     "iopub.status.idle": "2025-10-24T12:11:30.619234Z",
     "shell.execute_reply": "2025-10-24T12:11:30.618392Z",
     "shell.execute_reply.started": "2025-10-24T12:11:30.607605Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, test_size=0.1, seed=42):\n",
    "    return dataset.train_test_split(test_size=test_size, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e9b934c-aec4-4f4f-b08f-0a27e8540737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:11:32.215363Z",
     "iopub.status.busy": "2025-10-24T12:11:32.214198Z",
     "iopub.status.idle": "2025-10-24T12:11:32.230063Z",
     "shell.execute_reply": "2025-10-24T12:11:32.229258Z",
     "shell.execute_reply.started": "2025-10-24T12:11:32.215320Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_and_tokenizer(model_name):\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True,\n",
    "        bnb_8bit_compute_dtype=torch.float16,\n",
    "        bnb_8bit_use_double_quant=True\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    #tokenizer.model_max_length = 4096\n",
    "    with open(\"chat_template.jinja\", \"r\", encoding=\"utf-8\") as f:\n",
    "        chat_template = f.read()\n",
    "    tokenizer.chat_template = chat_template\n",
    "    print(tokenizer.chat_template)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "def get_lora_config():\n",
    "    return LoraConfig(\n",
    "        r=32,\n",
    "        lora_alpha=64,\n",
    "        lora_dropout=0.05,\n",
    "        target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14526a80-1d59-4f36-a9c1-92940d820bf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:11:34.512123Z",
     "iopub.status.busy": "2025-10-24T12:11:34.510752Z",
     "iopub.status.idle": "2025-10-24T12:11:34.534491Z",
     "shell.execute_reply": "2025-10-24T12:11:34.533642Z",
     "shell.execute_reply.started": "2025-10-24T12:11:34.512072Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_args():\n",
    "    return SFTConfig(\n",
    "        output_dir=\"./qwen-pg-hint-optimizer\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        gradient_accumulation_steps=16,\n",
    "        learning_rate=2e-4,\n",
    "        warmup_ratio=0.05,\n",
    "        logging_steps=1,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=100,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=100,\n",
    "        save_total_limit=3,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        bf16=torch.cuda.is_available() and torch.cuda.is_bf16_supported(),\n",
    "        fp16=False,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        max_grad_norm=0.3,\n",
    "        report_to=\"tensorboard\",\n",
    "        assistant_only_loss=True,\n",
    "        packing=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "596cdef6-5c4b-4dc4-90b7-aafca937eebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:11:36.352639Z",
     "iopub.status.busy": "2025-10-24T12:11:36.351620Z",
     "iopub.status.idle": "2025-10-24T12:11:36.368844Z",
     "shell.execute_reply": "2025-10-24T12:11:36.367978Z",
     "shell.execute_reply.started": "2025-10-24T12:11:36.352594Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''from transformers import TrainerCallback\n",
    "class DebugMaskCallback(TrainerCallback):\n",
    "    def on_train_batch_begin(self, args, state, control, inputs=None, **kwargs):\n",
    "        masks = inputs.get(\"assistant_masks\")\n",
    "        if masks is not None:\n",
    "            print(f\"Batch {state.global_step} assistant_masks:\", masks[0].tolist())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efbf6b75-81d0-44f7-bb34-f2a143f7b313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:11:38.348774Z",
     "iopub.status.busy": "2025-10-24T12:11:38.347696Z",
     "iopub.status.idle": "2025-10-24T12:11:38.362195Z",
     "shell.execute_reply": "2025-10-24T12:11:38.361472Z",
     "shell.execute_reply.started": "2025-10-24T12:11:38.348727Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "def main(json_path, model_name=\"Qwen/Qwen2.5-3B-Instruct\"):\n",
    "\n",
    "    dataset = prepare_training_dataset(json_path)\n",
    "    train_val = split_dataset(dataset)\n",
    "    train_ds, val_ds = train_val['train'], train_val['test']\n",
    "\n",
    "    print(f\"Training samples: {len(train_ds)}\")\n",
    "    print(f\"Validation samples: {len(val_ds)}\")\n",
    "    print(f\"Example training data:\")\n",
    "\n",
    "    model, tokenizer = get_model_and_tokenizer(model_name)\n",
    "    \n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    lora_config = get_lora_config()\n",
    "    training_args = get_training_args()\n",
    "    \n",
    "    '''data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        padding=\"longest\",     \n",
    "        max_length=None\n",
    "    )'''\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        peft_config=lora_config,\n",
    "        processing_class=tokenizer,\n",
    "        #callbacks=[DebugMaskCallback()]\n",
    "    )\n",
    "\n",
    "    print(\"Starting training\")\n",
    "    trainer.train()\n",
    "    trainer.save_model(\"./final_model\")\n",
    "    tokenizer.save_pretrained(\"./final_model\")\n",
    "    print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5faef362-912f-4283-8874-8871db5e37ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T18:20:15.577183Z",
     "iopub.status.busy": "2025-10-23T18:20:15.576247Z",
     "iopub.status.idle": "2025-10-23T18:35:54.404437Z",
     "shell.execute_reply": "2025-10-23T18:35:54.402016Z",
     "shell.execute_reply.started": "2025-10-23T18:20:15.577145Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 101\n",
      "Validation samples: 12\n",
      "Example training data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:43<00:43, 43.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:09<00:00, 34.78s/it]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{# — Последовательно рендерим user и assistant сообщения #}\n",
      "{% for message in messages %}\n",
      "  {% if message.role == \"user\" %}\n",
      "<|im_start|>user\n",
      "{{ message.content }}<|im_end|>\n",
      "  {% elif message.role == \"assistant\" %}\n",
      "<|im_start|>assistant\n",
      "{% generation %}\n",
      "{{ message.content }}\n",
      "{% endgeneration %}<|im_end|>\n",
      "  {% endif %}\n",
      "{% endfor %}\n",
      "\n",
      "{# — Гарантируем открытый ассистентский маркер на конце всегда #}\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tokenizing train dataset:   0%|          | 0/101 [00:00<?, ? examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Tokenizing train dataset:  16%|█▌        | 16/101 [00:00<00:00, 144.36 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Tokenizing train dataset:  32%|███▏      | 32/101 [00:00<00:00, 149.35 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Tokenizing train dataset:  49%|████▊     | 49/101 [00:00<00:00, 153.85 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Tokenizing train dataset:  71%|███████▏  | 72/101 [00:00<00:00, 148.12 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Tokenizing train dataset: 100%|██████████| 101/101 [00:00<00:00, 130.38 examples/s][A\u001b[A\n",
      "\n",
      "\n",
      "Truncating train dataset: 100%|██████████| 101/101 [00:00<00:00, 8820.92 examples/s]\n",
      "\n",
      "\n",
      "Tokenizing eval dataset:   0%|          | 0/12 [00:00<?, ? examples/s]\u001b[A\u001b[A\n",
      "\n",
      "Tokenizing eval dataset: 100%|██████████| 12/12 [00:00<00:00, 112.28 examples/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Truncating eval dataset: 100%|██████████| 12/12 [00:00<00:00, 2002.05 examples/s]\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2/21 [15:07<2:23:37, 453.55s/it]\n",
      "\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 1/21 [00:42<14:15, 42.79s/it]\u001b[A\n",
      "                                              \n",
      "  5%|▍         | 1/21 [03:16<14:04, 42.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.992, 'grad_norm': 13.2738618850708, 'learning_rate': 0.0, 'entropy': 0.8887458518147469, 'num_tokens': 16384.0, 'mean_token_accuracy': 0.0703125, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|▉         | 2/21 [01:25<13:29, 42.62s/it]\u001b[A\n",
      "                                              \n",
      "  5%|▍         | 1/21 [03:58<14:04, 42.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1673, 'grad_norm': 9.491329193115234, 'learning_rate': 0.0001, 'entropy': 0.9523928053677082, 'num_tokens': 32757.0, 'mean_token_accuracy': 0.04438405856490135, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 3/21 [02:07<12:44, 42.49s/it]\u001b[A\n",
      "                                              \n",
      "  5%|▍         | 1/21 [04:40<14:04, 42.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 0.0002, 'entropy': 0.9136723764240742, 'num_tokens': 49141.0, 'mean_token_accuracy': 0.0, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 4/21 [02:49<11:58, 42.26s/it]\u001b[A\n",
      "                                              \n",
      "  5%|▍         | 1/21 [05:22<14:04, 42.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0384, 'grad_norm': 8.501145362854004, 'learning_rate': 0.00018947368421052632, 'entropy': 0.9327629059553146, 'num_tokens': 65525.0, 'mean_token_accuracy': 0.048076923936605453, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 5/21 [03:31<11:13, 42.12s/it]\u001b[A\n",
      "                                              \n",
      "  5%|▍         | 1/21 [06:04<14:04, 42.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 0.00017894736842105264, 'entropy': 0.9802480526268482, 'num_tokens': 81909.0, 'mean_token_accuracy': 0.0, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▊       | 6/21 [04:13<10:30, 42.05s/it]\u001b[A\n",
      "                                              \n",
      "  5%|▍         | 1/21 [06:46<14:04, 42.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7005, 'grad_norm': 5.804986000061035, 'learning_rate': 0.00016842105263157895, 'entropy': 0.9683047607541084, 'num_tokens': 98281.0, 'mean_token_accuracy': 0.10947651043534279, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 7/21 [04:26<07:36, 32.61s/it]\u001b[A\n",
      "                                              \n",
      "  5%|▍         | 1/21 [06:59<14:04, 42.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 0.00015789473684210527, 'entropy': 1.0326840162277222, 'num_tokens': 103401.0, 'mean_token_accuracy': 0.0, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 8/21 [05:08<07:44, 35.70s/it]\u001b[A\n",
      "                                              \n",
      "  5%|▍         | 1/21 [07:42<14:04, 42.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4759, 'grad_norm': 2.258043050765991, 'learning_rate': 0.00014736842105263158, 'entropy': 1.0143660753965378, 'num_tokens': 119773.0, 'mean_token_accuracy': 0.057065218687057495, 'epoch': 1.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 9/21 [05:51<07:33, 37.81s/it]\u001b[A\n",
      "                                              \n",
      "  5%|▍         | 1/21 [08:24<14:04, 42.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 0.0001368421052631579, 'entropy': 0.9706712551414967, 'num_tokens': 136157.0, 'mean_token_accuracy': 0.0, 'epoch': 1.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 10/21 [06:33<07:09, 39.07s/it]\u001b[A\n",
      "                                               \n",
      "  5%|▍         | 1/21 [09:06<14:04, 42.22s/it]]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1513, 'grad_norm': 2.266556978225708, 'learning_rate': 0.0001263157894736842, 'entropy': 1.012984674423933, 'num_tokens': 152541.0, 'mean_token_accuracy': 0.23736806213855743, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 11/21 [07:15<06:39, 39.97s/it]\u001b[A\n",
      "                                               \n",
      "  5%|▍         | 1/21 [09:48<14:04, 42.22s/it]]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 0.00011578947368421053, 'entropy': 1.0012114867568016, 'num_tokens': 168925.0, 'mean_token_accuracy': 0.0, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████▋    | 12/21 [07:57<06:05, 40.56s/it]\u001b[A\n",
      "                                               \n",
      "  5%|▍         | 1/21 [10:30<14:04, 42.22s/it]]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2194, 'grad_norm': 2.631427049636841, 'learning_rate': 0.00010526315789473685, 'entropy': 0.940270908176899, 'num_tokens': 185298.0, 'mean_token_accuracy': 0.05978260934352875, 'epoch': 1.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████▏   | 13/21 [08:39<05:27, 41.00s/it]\u001b[A\n",
      "                                               \n",
      "  5%|▍         | 1/21 [11:12<14:04, 42.22s/it]]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 9.473684210526316e-05, 'entropy': 0.9713254682719707, 'num_tokens': 201682.0, 'mean_token_accuracy': 0.0, 'epoch': 1.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 14/21 [08:52<03:48, 32.63s/it]\u001b[A\n",
      "                                               \n",
      "  5%|▍         | 1/21 [11:25<14:04, 42.22s/it]]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 8.421052631578948e-05, 'entropy': 1.0138582944869996, 'num_tokens': 206802.0, 'mean_token_accuracy': 0.0, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████▏  | 15/21 [09:34<03:33, 35.56s/it]\u001b[A\n",
      "                                               \n",
      "  5%|▍         | 1/21 [12:08<14:04, 42.22s/it]]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 7.368421052631579e-05, 'entropy': 0.9687216058373451, 'num_tokens': 223186.0, 'mean_token_accuracy': 0.0, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|███████▌  | 16/21 [10:16<03:07, 37.55s/it]\u001b[A\n",
      "                                               \n",
      "  5%|▍         | 1/21 [12:50<14:04, 42.22s/it]]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1974, 'grad_norm': 1.998416781425476, 'learning_rate': 6.31578947368421e-05, 'entropy': 1.0288858115673065, 'num_tokens': 239570.0, 'mean_token_accuracy': 0.18333333358168602, 'epoch': 2.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|████████  | 17/21 [10:58<02:35, 38.86s/it]\u001b[A\n",
      "                                               \n",
      "  5%|▍         | 1/21 [13:32<14:04, 42.22s/it]]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5.2631578947368424e-05, 'entropy': 0.9828330390155315, 'num_tokens': 255954.0, 'mean_token_accuracy': 0.0, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|████████▌ | 18/21 [11:40<01:59, 39.79s/it]\u001b[A\n",
      "                                               \n",
      "  5%|▍         | 1/21 [14:14<14:04, 42.22s/it]]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2336, 'grad_norm': 3.5591208934783936, 'learning_rate': 4.210526315789474e-05, 'entropy': 0.9518195502460003, 'num_tokens': 272326.0, 'mean_token_accuracy': 0.05797101557254791, 'epoch': 2.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 19/21 [12:22<01:20, 40.43s/it]\u001b[A\n",
      "                                               \n",
      "  5%|▍         | 1/21 [14:55<14:04, 42.22s/it]]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0723, 'grad_norm': 1.5242300033569336, 'learning_rate': 3.157894736842105e-05, 'entropy': 0.9971456155180931, 'num_tokens': 288699.0, 'mean_token_accuracy': 0.06159420311450958, 'epoch': 2.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 20/21 [13:04<00:40, 40.96s/it]\u001b[A\n",
      "                                               \n",
      "  5%|▍         | 1/21 [15:38<14:04, 42.22s/it]]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0058, 'grad_norm': 0.16505832970142365, 'learning_rate': 2.105263157894737e-05, 'entropy': 0.958176739513874, 'num_tokens': 305083.0, 'mean_token_accuracy': 0.0625, 'epoch': 2.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 21/21 [13:18<00:00, 32.62s/it]\u001b[A\n",
      "                                               \n",
      "  5%|▍         | 1/21 [15:51<14:04, 42.22s/it]]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 1.0526315789473684e-05, 'entropy': 1.050365114212036, 'num_tokens': 310203.0, 'mean_token_accuracy': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: caa3216c-c793-4f4c-a124-1eab8fd2366e)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2.5-3B-Instruct/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "\n",
      "                                               \n",
      "100%|██████████| 21/21 [14:06<00:00, 40.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 846.9306, 'train_samples_per_second': 0.358, 'train_steps_per_second': 0.025, 'train_loss': 0.39304245658041465, 'epoch': 3.0}\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "main('all_queries_statistics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70b2765c-8c00-42c0-baf1-f5c0110dc165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:12:34.092894Z",
     "iopub.status.busy": "2025-10-24T12:12:34.092213Z",
     "iopub.status.idle": "2025-10-24T12:12:34.112076Z",
     "shell.execute_reply": "2025-10-24T12:12:34.111377Z",
     "shell.execute_reply.started": "2025-10-24T12:12:34.092853Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% if messages[0].role == \"system\" %}\n",
      "<|im_start|>system\n",
      "{{ messages[0].content }}<|im_end|>\n",
      "{% else %}\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "{% endif %}\n",
      "\n",
      "\n",
      "{% for message in messages %}\n",
      "  {% if message.role == \"user\" %}\n",
      "<|im_start|>user\n",
      "{{ message.content }}<|im_end|>\n",
      "  {% elif message.role == \"assistant\" %}\n",
      "<|im_start|>assistant\n",
      "{% generation %}\n",
      "{{ message.content }}\n",
      "{% endgeneration %}<|im_end|>\n",
      "  {% endif %}\n",
      "{% endfor %}\n",
      "\n",
      "\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"chat_template.jinja\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chat_template = f.read()\n",
    "tokenizer.chat_template = chat_template\n",
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b7e962b-b622-444e-b774-79b370662f57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:12:36.270213Z",
     "iopub.status.busy": "2025-10-24T12:12:36.269126Z",
     "iopub.status.idle": "2025-10-24T12:12:36.294857Z",
     "shell.execute_reply": "2025-10-24T12:12:36.293934Z",
     "shell.execute_reply.started": "2025-10-24T12:12:36.270170Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b0721e0-d0d6-4c7b-9793-2bdcd0dfc071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:12:48.170484Z",
     "iopub.status.busy": "2025-10-24T12:12:48.169280Z",
     "iopub.status.idle": "2025-10-24T12:12:48.310091Z",
     "shell.execute_reply": "2025-10-24T12:12:48.309045Z",
     "shell.execute_reply.started": "2025-10-24T12:12:48.170439Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant_masks: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "example = {\n",
    "    \"messages\": [\n",
    "        prepare_training_dataset('all_queries_statistics.json')[0]['messages'][1],\n",
    "        prepare_training_dataset('all_queries_statistics.json')[0]['messages'][2]\n",
    "    ]\n",
    "}\n",
    "out = tokenizer.apply_chat_template(\n",
    "    example[\"messages\"],\n",
    "    tokenize=True,\n",
    "    return_dict=True,\n",
    "    return_assistant_tokens_mask=True\n",
    ")\n",
    "print(\"assistant_masks:\", out['assistant_masks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "371b164c-a3cd-4605-94cf-3b22a0a294b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:15:46.466142Z",
     "iopub.status.busy": "2025-10-24T12:15:46.464854Z",
     "iopub.status.idle": "2025-10-24T12:15:46.479762Z",
     "shell.execute_reply": "2025-10-24T12:15:46.478910Z",
     "shell.execute_reply.started": "2025-10-24T12:15:46.466090Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_hints_for_query(query, statistics, model, tokenizer):\n",
    "    user_prompt = USER_PROMPT_TEMPLATE.format(\n",
    "        query=query,\n",
    "        card_tb=statistics[\"Card_Tb\"],\n",
    "        ndv=format_ndv_stats(statistics[\"NDV\"]),\n",
    "        main_value=format_main_values(statistics[\"Main_Value\"]),\n",
    "        min_max=format_min_max(statistics[\"Min_Max\"])\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT.strip()},\n",
    "        {\"role\": \"user\", \"content\": user_prompt.strip()},\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ead319a-274d-4e22-afc2-73c0a14faeb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:07:00.745833Z",
     "iopub.status.busy": "2025-10-24T12:07:00.744491Z",
     "iopub.status.idle": "2025-10-24T12:08:06.495368Z",
     "shell.execute_reply": "2025-10-24T12:08:06.494487Z",
     "shell.execute_reply.started": "2025-10-24T12:07:00.745783Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:48<00:00, 24.20s/it]\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\"./final_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12590a2d-00c8-4994-92fb-c7fa165c61d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:50:41.999970Z",
     "iopub.status.busy": "2025-10-24T12:50:41.998673Z",
     "iopub.status.idle": "2025-10-24T12:52:22.599317Z",
     "shell.execute_reply": "2025-10-24T12:52:22.598425Z",
     "shell.execute_reply.started": "2025-10-24T12:50:41.999922Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "You are an expert PostgreSQL query optimizer specialized in generating pg_hint_plan commands. Your task is to analyze SQL queries along with their database statistics and generate optimal hint commands to improve query execution plans.\n",
      "\n",
      "pg_hint_plan hints include:\n",
      "- Scan method hints: SeqScan, IndexScan, BitmapScan, TidScan\n",
      "- Join method hints: NestLoop, HashJoin, MergeJoin\n",
      "- Join order hints: Leading(...)\n",
      "- Row number correction hints: Rows(...)\n",
      "Generate hints that will result in the most efficient execution plan based on the provided statistics.\n",
      "\n",
      "\n",
      "user\n",
      "Analyze the following PostgreSQL query and generate optimal pg_hint_plan commands.\n",
      "\n",
      "**Query:**\n",
      "SELECT MIN(chn.name) AS uncredited_voiced_character,\n",
      "       MIN(t.title) AS russian_movie\n",
      "FROM char_name AS chn,\n",
      "     cast_info AS ci,\n",
      "     company_name AS cn,\n",
      "     company_type AS ct,\n",
      "     movie_companies AS mc,\n",
      "     role_type AS rt,\n",
      "     title AS t\n",
      "WHERE ci.note LIKE '%(voice)%'\n",
      "  AND ci.note LIKE '%(uncredited)%'\n",
      "  AND cn.country_code = '[ru]'\n",
      "  AND rt.role = 'actor'\n",
      "  AND t.production_year > 2005\n",
      "  AND t.id = mc.movie_id\n",
      "  AND t.id = ci.movie_id\n",
      "  AND ci.movie_id = mc.movie_id\n",
      "  AND chn.id = ci.person_role_id\n",
      "  AND rt.id = ci.role_id\n",
      "  AND cn.id = mc.company_id\n",
      "  AND ct.id = mc.company_type_id;\n",
      "**Table Cardinalities:**\n",
      "rt : 1 (12)\n",
      "ci : 2746 (63439712)\n",
      "t : 1 (3298978)\n",
      "mc : 6 (4954445)\n",
      "cn : 1 (362131)\n",
      "chn : 1 (4314880)\n",
      "ct : 4 (4)\n",
      "\n",
      "**Column Statistics (NDV):**\n",
      "  - char_name.name_pcode_nf: 12420.0\n",
      "  - char_name.id: -1.0\n",
      "  - char_name.name: -1.0\n",
      "  - char_name.imdb_index: 0.0\n",
      "  - char_name.imdb_id: 0.0\n",
      "  - char_name.md5sum: -1.0\n",
      "  - char_name.surname_pcode: 4954.0\n",
      "  - cast_info.person_role_id: 20143.0\n",
      "  - cast_info.person_id: 65346.0\n",
      "  - cast_info.movie_id: 1719595.0\n",
      "  - cast_info.note: 4263.0\n",
      "  - cast_info.id: -1.0\n",
      "  - cast_info.nr_order: 145.0\n",
      "  - cast_info.role_id: 11.0\n",
      "  - company_name.name_pcode_sf: 11132.0\n",
      "  - company_name.md5sum: -1.0\n",
      "  - company_name.id: -1.0\n",
      "  - company_name.imdb_id: 0.0\n",
      "  - company_name.country_code: 173.0\n",
      "  - company_name.name: -0.87158513\n",
      "  - company_name.name_pcode_nf: 11834.0\n",
      "  - company_type.id: -1.0\n",
      "  - company_type.kind: -1.0\n",
      "  - movie_companies.company_id: 20333.0\n",
      "  - movie_companies.note: 6353.0\n",
      "  - movie_companies.movie_id: -0.16448805\n",
      "  - movie_companies.id: -1.0\n",
      "  - movie_companies.company_type_id: 2.0\n",
      "  - role_type.id: -1.0\n",
      "  - role_type.role: -1.0\n",
      "  - title.imdb_index: 12.0\n",
      "  - title.kind_id: 6.0\n",
      "  - title.imdb_id: 0.0\n",
      "  - title.id: -1.0\n",
      "  - title.title: 78695.0\n",
      "  - title.episode_nr: 1917.0\n",
      "  - title.episode_of_id: 20982.0\n",
      "  - title.series_years: 271.0\n",
      "  - title.md5sum: -1.0\n",
      "  - title.phonetic_code: 10595.0\n",
      "  - title.season_nr: 74.0\n",
      "  - title.production_year: 118.0\n",
      "\n",
      "**Most Frequent Values:**\n",
      "  - char_name.name_pcode_nf: ['H5241', 143110]\n",
      "  - char_name.surname_pcode: ['M5', 36245]\n",
      "  - cast_info.person_role_id: ['2', 2159065]\n",
      "  - cast_info.person_id: ['2554625', 27491]\n",
      "  - cast_info.note: ['(producer)', 2634863]\n",
      "  - cast_info.nr_order: ['1', 2087167]\n",
      "  - cast_info.role_id: ['1', 20427587]\n",
      "  - company_name.name_pcode_sf: ['L2145', 1123]\n",
      "  - company_name.country_code: ['[us]', 139312]\n",
      "  - company_name.name: ['AXN', 72]\n",
      "  - company_name.name_pcode_nf: ['P6325', 1171]\n",
      "  - movie_companies.company_id: ['67', 75142]\n",
      "  - movie_companies.note: ['(in association with)', 47728]\n",
      "  - movie_companies.company_type_id: ['2', 2889102]\n",
      "  - title.kind_id: ['7', 3025933]\n",
      "  - title.title: ['(#1.1)', 25622]\n",
      "  - title.episode_nr: ['1', 143616]\n",
      "  - title.episode_of_id: ['628404', 10887]\n",
      "  - title.series_years: ['2015-????', 8467]\n",
      "  - title.phonetic_code: ['A1416', 9567]\n",
      "  - title.season_nr: ['1', 1308265]\n",
      "  - title.production_year: ['2014', 189251]\n",
      "\n",
      "**Value Ranges (Min/Max):**\n",
      "  - char_name.id: [1, 4314864]\n",
      "  - cast_info.id: [1, 63475835]\n",
      "  - cast_info.person_id: [1, 6226526]\n",
      "  - cast_info.movie_id: [1, 4730370]\n",
      "  - cast_info.person_role_id: [1, 4314864]\n",
      "  - cast_info.nr_order: [-2068070866, 1776839230]\n",
      "  - cast_info.role_id: [1, 11]\n",
      "  - company_name.id: [1, 362131]\n",
      "  - company_type.id: [1, 4]\n",
      "  - movie_companies.id: [1, 4958296]\n",
      "  - movie_companies.movie_id: [2, 4698791]\n",
      "  - movie_companies.company_id: [1, 362131]\n",
      "  - movie_companies.company_type_id: [1, 2]\n",
      "  - role_type.id: [1, 12]\n",
      "  - title.id: [100000, 3399999]\n",
      "  - title.kind_id: [1, 8]\n",
      "  - title.production_year: [1888, 2115]\n",
      "  - title.episode_of_id: [99685, 3300011]\n",
      "  - title.season_nr: [1, 2015]\n",
      "  - title.episode_nr: [1, 91334]\n",
      "Generate the optimal pg_hint_plan hints for this query.\n",
      "\n",
      "\n",
      "assistant\n",
      "IndexScan rt\n",
      "IndexScan ci\n",
      "IndexScan t\n",
      "IndexScan mc\n",
      "IndexScan cn\n",
      "IndexScan chn\n",
      "IndexScan ct\n",
      "Leading(rt ci t mc cn chn ct)\n"
     ]
    }
   ],
   "source": [
    "test_statistics = {\"Card_Tb\": \"rt : 1 (12)\\nci : 2746 (63439712)\\nt : 1 (3298978)\\nmc : 6 (4954445)\\ncn : 1 (362131)\\nchn : 1 (4314880)\\nct : 4 (4)\",\n",
    "    \"NDV\": \"char_name.name_pcode_nf : 12420.0\\nchar_name.id : -1.0\\nchar_name.name : -1.0\\nchar_name.imdb_index : 0.0\\nchar_name.imdb_id : 0.0\\nchar_name.md5sum : -1.0\\nchar_name.surname_pcode : 4954.0\\ncast_info.person_role_id : 20143.0\\ncast_info.person_id : 65346.0\\ncast_info.movie_id : 1719595.0\\ncast_info.note : 4263.0\\ncast_info.id : -1.0\\ncast_info.nr_order : 145.0\\ncast_info.role_id : 11.0\\ncompany_name.name_pcode_sf : 11132.0\\ncompany_name.md5sum : -1.0\\ncompany_name.id : -1.0\\ncompany_name.imdb_id : 0.0\\ncompany_name.country_code : 173.0\\ncompany_name.name : -0.87158513\\ncompany_name.name_pcode_nf : 11834.0\\ncompany_type.id : -1.0\\ncompany_type.kind : -1.0\\nmovie_companies.company_id : 20333.0\\nmovie_companies.note : 6353.0\\nmovie_companies.movie_id : -0.16448805\\nmovie_companies.id : -1.0\\nmovie_companies.company_type_id : 2.0\\nrole_type.id : -1.0\\nrole_type.role : -1.0\\ntitle.imdb_index : 12.0\\ntitle.kind_id : 6.0\\ntitle.imdb_id : 0.0\\ntitle.id : -1.0\\ntitle.title : 78695.0\\ntitle.episode_nr : 1917.0\\ntitle.episode_of_id : 20982.0\\ntitle.series_years : 271.0\\ntitle.md5sum : -1.0\\ntitle.phonetic_code : 10595.0\\ntitle.season_nr : 74.0\\ntitle.production_year : 118.0\",\n",
    "    \"Main_Value\": \"char_name.name_pcode_nf : ['H5241', 143110]\\nchar_name.surname_pcode : ['M5', 36245]\\ncast_info.person_role_id : ['2', 2159065]\\ncast_info.person_id : ['2554625', 27491]\\ncast_info.note : ['(producer)', 2634863]\\ncast_info.nr_order : ['1', 2087167]\\ncast_info.role_id : ['1', 20427587]\\ncompany_name.name_pcode_sf : ['L2145', 1123]\\ncompany_name.country_code : ['[us]', 139312]\\ncompany_name.name : ['AXN', 72]\\ncompany_name.name_pcode_nf : ['P6325', 1171]\\nmovie_companies.company_id : ['67', 75142]\\nmovie_companies.note : ['(in association with)', 47728]\\nmovie_companies.company_type_id : ['2', 2889102]\\ntitle.kind_id : ['7', 3025933]\\ntitle.title : ['(#1.1)', 25622]\\ntitle.episode_nr : ['1', 143616]\\ntitle.episode_of_id : ['628404', 10887]\\ntitle.series_years : ['2015-????', 8467]\\ntitle.phonetic_code : ['A1416', 9567]\\ntitle.season_nr : ['1', 1308265]\\ntitle.production_year : ['2014', 189251]\",\n",
    "    \"Min_Max\": \"char_name.id : [1, 4314864]\\ncast_info.id : [1, 63475835]\\ncast_info.person_id : [1, 6226526]\\ncast_info.movie_id : [1, 4730370]\\ncast_info.person_role_id : [1, 4314864]\\ncast_info.nr_order : [-2068070866, 1776839230]\\ncast_info.role_id : [1, 11]\\ncompany_name.id : [1, 362131]\\ncompany_type.id : [1, 4]\\nmovie_companies.id : [1, 4958296]\\nmovie_companies.movie_id : [2, 4698791]\\nmovie_companies.company_id : [1, 362131]\\nmovie_companies.company_type_id : [1, 2]\\nrole_type.id : [1, 12]\\ntitle.id : [100000, 3399999]\\ntitle.kind_id : [1, 8]\\ntitle.production_year : [1888, 2115]\\ntitle.episode_of_id : [99685, 3300011]\\ntitle.season_nr : [1, 2015]\\ntitle.episode_nr : [1, 91334]\"}\n",
    "sql = \"SELECT MIN(chn.name) AS uncredited_voiced_character,\\n       MIN(t.title) AS russian_movie\\nFROM char_name AS chn,\\n     cast_info AS ci,\\n     company_name AS cn,\\n     company_type AS ct,\\n     movie_companies AS mc,\\n     role_type AS rt,\\n     title AS t\\nWHERE ci.note LIKE '%(voice)%'\\n  AND ci.note LIKE '%(uncredited)%'\\n  AND cn.country_code = '[ru]'\\n  AND rt.role = 'actor'\\n  AND t.production_year > 2005\\n  AND t.id = mc.movie_id\\n  AND t.id = ci.movie_id\\n  AND ci.movie_id = mc.movie_id\\n  AND chn.id = ci.person_role_id\\n  AND rt.id = ci.role_id\\n  AND cn.id = mc.company_id\\n  AND ct.id = mc.company_type_id;\"\n",
    "hints = generate_hints_for_query(sql, test_statistics, model, tokenizer)\n",
    "print(hints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ffe9e-d9c1-49f9-9b75-6969255409bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
