{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlDEySyDrsxW",
        "outputId": "cc7dc8ff-9af1-4200-aed2-7a4d1a6f7e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/drive/My Drive/trl')"
      ],
      "metadata": {
        "id": "swnzzaw1VV7C"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import GRPOTrainer, GRPOConfig"
      ],
      "metadata": {
        "id": "2DcwU_KSVgLD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"vllm==0.10.2\"\n",
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "869tpnjPA6jc",
        "outputId": "63205a98-a721-4de1-8891-edb7e7856408"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vllm==0.10.2 in /usr/local/lib/python3.12/dist-packages (0.10.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (2025.11.3)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (6.2.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (4.67.1)\n",
            "Requirement already satisfied: blake3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.0.8)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.55.2 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (4.57.2)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.22.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (5.29.5)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.10.2) (0.118.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (3.13.2)\n",
            "Requirement already satisfied: openai>=1.99.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (2.8.1)\n",
            "Requirement already satisfied: pydantic>=2.11.7 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (2.12.3)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.23.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (11.3.0)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (7.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.12.0)\n",
            "Requirement already satisfied: lm-format-enforcer==0.11.3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.11.3)\n",
            "Requirement already satisfied: llguidance<0.8.0,>=0.7.11 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.7.30)\n",
            "Requirement already satisfied: outlines_core==0.2.11 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.2.11)\n",
            "Requirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (5.6.3)\n",
            "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.2.2)\n",
            "Requirement already satisfied: xgrammar==0.1.23 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.1.23)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (4.15.0)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (3.20.0)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.2.1.1.post7)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (26.2.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.20.0)\n",
            "Requirement already satisfied: gguf>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.17.1)\n",
            "Requirement already satisfied: mistral_common>=1.8.2 in /usr/local/lib/python3.12/dist-packages (from mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (1.8.6)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (4.12.0.88)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (6.0.3)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.17.0)\n",
            "Requirement already satisfied: setuptools<80,>=77.0.3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (79.0.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.11.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.11.0)\n",
            "Requirement already satisfied: depyf==0.19.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.19.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (3.1.2)\n",
            "Requirement already satisfied: watchfiles in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.1.1)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (4.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.16.3)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.13.0)\n",
            "Requirement already satisfied: pybase64 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.4.2)\n",
            "Requirement already satisfied: cbor2 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (5.7.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.3.7)\n",
            "Requirement already satisfied: openai-harmony>=0.0.3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.0.8)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.61.2)\n",
            "Requirement already satisfied: ray>=2.48.0 in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm==0.10.2) (2.52.1)\n",
            "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (2.8.0)\n",
            "Requirement already satisfied: torchaudio==2.8.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (2.8.0)\n",
            "Requirement already satisfied: torchvision==0.23.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.23.0)\n",
            "Requirement already satisfied: xformers==0.0.32.post1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.0.32.post1)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from compressed-tensors==0.11.0->vllm==0.10.2) (2.4.7)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.12/dist-packages (from depyf==0.19.0->vllm==0.10.2) (0.8.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.19.0->vllm==0.10.2) (0.3.8)\n",
            "Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from lm-format-enforcer==0.11.3->vllm==0.10.2) (0.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lm-format-enforcer==0.11.3->vllm==0.10.2) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.61.2->vllm==0.10.2) (0.44.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (3.4.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.48.0)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.8 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.0.16)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.10.2) (0.28.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.10.2) (0.0.20)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.10.2) (2.3.0)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.38.0)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (4.25.1)\n",
            "Requirement already satisfied: pydantic-extra-types>=2.10.5 in /usr/local/lib/python3.12/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (2.10.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm==0.10.2) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm==0.10.2) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm==0.10.2) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm==0.10.2) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm==0.10.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm==0.10.2) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm==0.10.2) (0.4.2)\n",
            "Requirement already satisfied: click!=8.3.*,>=7.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm==0.10.2) (8.2.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm==0.10.2) (1.1.2)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm==0.10.2) (13.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.10.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.10.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.10.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.10.2) (2025.11.12)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.21.1->vllm==0.10.2) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.55.2->vllm==0.10.2) (0.7.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (1.22.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm==0.10.2) (2.8.0)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.20.0)\n",
            "Requirement already satisfied: rich-toolkit>=0.14.8 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.17.0)\n",
            "Requirement already satisfied: fastapi-cloud-cli>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.6.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.23.0->fastapi[standard]>=0.115.0->vllm==0.10.2) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.23.0->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.1->vllm==0.10.2) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0->vllm==0.10.2) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (0.29.0)\n",
            "Requirement already satisfied: pycountry>=23 in /usr/local/lib/python3.12/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (24.6.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->vllm==0.10.2) (1.3.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (1.2.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.22.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm==0.10.2) (0.8.3)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (0.13.1)\n",
            "Requirement already satisfied: soxr>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (1.0.0)\n",
            "Requirement already satisfied: rignore>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.7.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (2.46.0)\n",
            "Requirement already satisfied: fastar>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.8.0)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (13.9.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (2.0.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (2.23)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.1.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (79.0.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qeRvtWlkqr5M"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import torch\n",
        "import psycopg2\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainerCallback,\n",
        "    TrainerState,\n",
        "    TrainerControl,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import re\n",
        "from typing import List, Sequence, Dict, Any, Tuple\n",
        "import warnings\n",
        "import numpy as np\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WCdRg7TqNpSQ"
      },
      "outputs": [],
      "source": [
        "class ConsoleLoggingCallback(TrainerCallback):\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is not None:\n",
        "            print(f\"Step {state.global_step}: {logs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "49BASKpmhjv-"
      },
      "outputs": [],
      "source": [
        "grammar = r\"\"\"\n",
        "root ::= hint_comment\n",
        "\n",
        "# /*+ SeqScan(t) IndexScan(t idx) Leading((t1 t2) t3) */\n",
        "hint_comment ::= \"/*+\" wsp? hint_list wsp? \"*/\"\n",
        "\n",
        "hint_list ::= hint (wsp hint)*\n",
        "\n",
        "hint ::= scan_hint\n",
        "       | join_hint\n",
        "       | leading_hint\n",
        "\n",
        "# --- Scan hints --------------------------------------------------------\n",
        "\n",
        "scan_hint ::=\n",
        "      \"SeqScan\" \"(\" wsp? rel_name wsp? \")\"\n",
        "    | \"IndexScan\" \"(\" wsp? rel_name (wsp index_name)* wsp? \")\"\n",
        "    | \"IndexOnlyScan\" \"(\" wsp? rel_name (wsp index_name)* wsp? \")\"\n",
        "    | \"BitmapScan\" \"(\" wsp? rel_name (wsp index_name)* wsp? \")\"\n",
        "    | \"NoSeqScan\" \"(\" wsp? rel_name wsp? \")\"\n",
        "    | \"NoIndexScan\" \"(\" wsp? rel_name wsp? \")\"\n",
        "    | \"NoIndexOnlyScan\" \"(\" wsp? rel_name wsp? \")\"\n",
        "    | \"NoBitmapScan\" \"(\" wsp? rel_name wsp? \")\"\n",
        "\n",
        "# --- Join method hints -------------------------------------------------\n",
        "\n",
        "join_hint ::= join_method_hint | no_join_method_hint\n",
        "\n",
        "join_method_hint ::=\n",
        "      \"NestLoop\"  \"(\" wsp? join_rel_list wsp? \")\"\n",
        "    | \"HashJoin\"  \"(\" wsp? join_rel_list wsp? \")\"\n",
        "    | \"MergeJoin\" \"(\" wsp? join_rel_list wsp? \")\"\n",
        "\n",
        "no_join_method_hint ::=\n",
        "      \"NoNestLoop\"  \"(\" wsp? join_rel_list wsp? \")\"\n",
        "    | \"NoHashJoin\"  \"(\" wsp? join_rel_list wsp? \")\"\n",
        "    | \"NoMergeJoin\" \"(\" wsp? join_rel_list wsp? \")\"\n",
        "\n",
        "# минимум две таблицы, дальше [ table... ]\n",
        "join_rel_list ::= rel_name wsp rel_name (wsp rel_name)*\n",
        "\n",
        "# --- Leading -----------------------------------------------------------\n",
        "\n",
        "# Две формы:\n",
        "#  1) Leading(a b c)\n",
        "#  2) Leading((a b) c) и рекурсивно вложенные пары\n",
        "leading_hint ::=\n",
        "      \"Leading\" \"(\" wsp leading_list wsp \")\"\n",
        "    | \"Leading\" \"(\" wsp join_member wsp \")\"\n",
        "\n",
        "# Простая линейная форма: Leading(t1 t2 [t3...])\n",
        "leading_list ::= rel_name wsp rel_name (wsp rel_name)*\n",
        "\n",
        "# Рекурсивный join-pair:\n",
        "# join_member -> \"t\" | \"(\" join_member join_member \")\"\n",
        "join_member ::=\n",
        "      rel_name\n",
        "    | \"(\" wsp? join_member wsp join_member wsp? \")\"\n",
        "\n",
        "# --- Idents, whitespace ------------------------------------------------\n",
        "\n",
        "rel_name   ::= ident\n",
        "index_name ::= ident\n",
        "\n",
        "ident ::= ident_start ident_part*\n",
        "ident_start ::= [A-Za-z_]\n",
        "ident_part  ::= [A-Za-z0-9_$.]\n",
        "\n",
        "# один пробельный символ\n",
        "ws ::= \" \" | \"\\t\" | \"\\n\" | \"\\r\"\n",
        "\n",
        "# один или больше пробельных символов\n",
        "wsp ::= ws ws*\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "v7TBOTirqvpP"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"\"\"You are an expert PostgreSQL query optimizer specialized in generating pg_hint_plan commands.\n",
        "\n",
        "Your task: Analyze SQL queries with database statistics and generate optimal hint commands.\n",
        "\n",
        "Available hints:\n",
        "- Scan methods: SeqScan(table), IndexScan(table), BitmapScan(table), TidScan(table)\n",
        "- Join methods: NestLoop(t1 t2), HashJoin(t1 t2), MergeJoin(t1 t2)\n",
        "- Join order: Leading((t1 t2) t3)\n",
        "- Row estimates: Rows(table_name #rows)\n",
        "\n",
        "Output: Generate ONLY valid pg_hint_plan() hints, one per line. No explanations.\"\"\"\n",
        "\n",
        "USER_PROMPT_TEMPLATE = \"\"\"Query: {query}\n",
        "\n",
        "Cardinalities: {card_tb}\n",
        "Statistics (NDV): {ndv}\n",
        "Frequent values: {main_value}\n",
        "Ranges: {min_max}\n",
        "\n",
        "Output: One hint per line, no explanation.\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "mEBoFeM6qxfS"
      },
      "outputs": [],
      "source": [
        "DB_CONFIG = {\n",
        "    \"host\": \"91.219.226.145\",\n",
        "    \"port\": 5432,\n",
        "    \"database\": \"testdb\",\n",
        "    \"user\": \"admin\",\n",
        "    \"password\": \"superadmin\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "meWX-HWQsHR8"
      },
      "outputs": [],
      "source": [
        "def format_ndv_stats(ndv_string):\n",
        "    lines = ndv_string.strip().split('\\n')\n",
        "    formatted = [f\"  - {x.replace(' : ', ': ')}\" for x in lines if ' : ' in x]\n",
        "    return '\\n'.join(formatted)\n",
        "\n",
        "def format_main_values(main_value_string):\n",
        "    lines = main_value_string.strip().split('\\n')\n",
        "    formatted = [f\"  - {x.replace(' : ', ': ')}\" for x in lines if ' : ' in x]\n",
        "    return '\\n'.join(formatted)\n",
        "\n",
        "def format_min_max(min_max_string):\n",
        "    lines = min_max_string.strip().split('\\n')\n",
        "    formatted = [f\"  - {x.replace(' : ', ': ')}\" for x in lines if ' : ' in x]\n",
        "    return '\\n'.join(formatted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zZmiMCkPtGQv"
      },
      "outputs": [],
      "source": [
        "def prepare_grpo_dataset(json_path: str, tokenizer) -> Dataset:\n",
        "\n",
        "    with open(json_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    data = data[63:]\n",
        "    prompts = []\n",
        "    queries = []\n",
        "    hints_gt = []\n",
        "\n",
        "    for record in data:\n",
        "\n",
        "        system_content = SYSTEM_PROMPT.strip()\n",
        "        user_content = USER_PROMPT_TEMPLATE.format(\n",
        "            query=record['query'],\n",
        "            card_tb=record['Card_Tb'],\n",
        "            ndv=format_ndv_stats(record['NDV']),\n",
        "            main_value=format_main_values(record['Main_Value']),\n",
        "            min_max=format_min_max(record['Min_Max'])\n",
        "        ).strip()\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_content},\n",
        "            {\"role\": \"user\", \"content\": user_content},\n",
        "        ]\n",
        "\n",
        "        prompt = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        prompts.append(prompt)\n",
        "        queries.append(record['query'])\n",
        "        hints_gt.append(record['best_hints'])\n",
        "\n",
        "    return Dataset.from_dict({\n",
        "        'prompt': prompts,\n",
        "        'query': queries,\n",
        "        'hints_gt': hints_gt\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ENJ_HKvy4-y0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def extract_hints_from_completion(completion: str) -> str:\n",
        "    debug_entry = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"completion_raw\": completion,\n",
        "        \"completion_length\": len(completion),\n",
        "        \"has_assistant\": 'assistant' in completion.lower(),\n",
        "    }\n",
        "\n",
        "    with open(\"completions_debug.jsonl\", 'a', encoding='utf-8') as f:\n",
        "        json.dump(debug_entry, f, ensure_ascii=False)\n",
        "        f.write('\\n')\n",
        "\n",
        "\n",
        "    if 'assistant' in completion.lower():\n",
        "        parts = completion.split('assistant')\n",
        "        if len(parts) > 1:\n",
        "            hints_text = parts[-1].strip()\n",
        "        else:\n",
        "            hints_text = completion\n",
        "    else:\n",
        "        hints_text = completion\n",
        "\n",
        "    hints_text = hints_text.replace('<|im_end|>', '').replace('<|endoftext|>', '').strip()\n",
        "\n",
        "    return hints_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "g4O9-OjTr82y"
      },
      "outputs": [],
      "source": [
        "def get_db_connection():\n",
        "    return psycopg2.connect(**DB_CONFIG)\n",
        "\n",
        "def execute_query_with_hints(query: str, hints: str = None, cursor=None) -> tuple:\n",
        "    if cursor is None:\n",
        "        return False, float('inf'), \"cursor is None\"\n",
        "\n",
        "    try:\n",
        "        try:\n",
        "            cursor.execute(\"LOAD 'pg_hint_plan';\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        if hints and hints.strip():\n",
        "            full_query = f\"/*+ {hints} */ {query}\"\n",
        "        else:\n",
        "            full_query = query\n",
        "\n",
        "        cursor.execute(\"EXPLAIN (ANALYZE, FORMAT JSON) \" + full_query)\n",
        "        result = cursor.fetchone()\n",
        "\n",
        "        if result and result[0]:\n",
        "            exec_time = result[0][0].get('Execution Time', 0)\n",
        "            return True, exec_time, None\n",
        "\n",
        "        print(f\"no execution plan\")\n",
        "        return False, float('inf'), \"no execution plan\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "        return False, float('inf'), str(e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "kFjmkHOdtch-"
      },
      "outputs": [],
      "source": [
        "def reward_func(completions: Sequence[str], **kwargs) -> List[float]:\n",
        "\n",
        "    conn = None\n",
        "    cursor = None\n",
        "\n",
        "    conn = get_db_connection()\n",
        "    if not conn:\n",
        "        return False, float('inf'), \"сonnection failed\"\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "\n",
        "    queries = kwargs.get('query', [None] * len(completions))\n",
        "\n",
        "    num_generations = kwargs.get('num_generations', 4)\n",
        "\n",
        "    all_rewards = []\n",
        "\n",
        "    for i in range(0, len(completions), num_generations):\n",
        "        group_completions = completions[i:i+num_generations]\n",
        "        group_queries = queries[i:i+num_generations]\n",
        "\n",
        "        query = group_queries[0]\n",
        "\n",
        "        execution_results = []\n",
        "        for completion in group_completions:\n",
        "            hints = extract_hints_from_completion(completion)\n",
        "            success, exec_time, error = execute_query_with_hints(query, hints, cursor)\n",
        "            print(success, exec_time, error)\n",
        "            execution_results.append({\n",
        "                'success': success,\n",
        "                'time': exec_time if success else float('inf'),\n",
        "                'hints': hints,\n",
        "                'completion': completion\n",
        "            })\n",
        "        success_baseline, time_baseline, error = execute_query_with_hints(query, None, cursor)\n",
        "        print(success, exec_time, error)\n",
        "        if not success_baseline:\n",
        "            time_baseline = float('inf')\n",
        "\n",
        "        ranks = compute_ranks([r['time'] for r in execution_results])\n",
        "        group_rewards = []\n",
        "        for rank, result in zip(ranks, execution_results):\n",
        "            reward = compute_reward_hybrid(\n",
        "                rank=rank,\n",
        "                time_execution=result['time'],\n",
        "                time_baseline=time_baseline,\n",
        "                num_generations=num_generations,\n",
        "                beta=0.7\n",
        "            )\n",
        "\n",
        "            group_rewards.append(reward)\n",
        "\n",
        "            print(f\"Rank {rank}: time={result['time']:.2f}ms, \"\n",
        "                  f\"reward={reward:.3f}\")\n",
        "\n",
        "        all_rewards.extend(group_rewards)\n",
        "\n",
        "    return all_rewards\n",
        "\n",
        "\n",
        "def compute_ranks(times: List[float]) -> List[int]:\n",
        "\n",
        "    sorted_indices = sorted(range(len(times)), key=lambda i: times[i])\n",
        "\n",
        "    ranks = [0] * len(times)\n",
        "    current_rank = 1\n",
        "\n",
        "    i = 0\n",
        "    while i < len(sorted_indices):\n",
        "        current_time = times[sorted_indices[i]]\n",
        "        j = i\n",
        "\n",
        "        while j < len(sorted_indices) and times[sorted_indices[j]] == current_time:\n",
        "            ranks[sorted_indices[j]] = current_rank\n",
        "            j += 1\n",
        "\n",
        "        current_rank += (j - i)\n",
        "        i = j\n",
        "\n",
        "    return ranks\n",
        "\n",
        "\n",
        "def compute_reward_hybrid(\n",
        "    rank: int,\n",
        "    time_execution: float,\n",
        "    time_baseline: float,\n",
        "    num_generations: int,\n",
        "    beta: float = 0.7\n",
        ") -> float:\n",
        "\n",
        "    if num_generations == 1:\n",
        "        rank_reward = 0.0\n",
        "    else:\n",
        "        rank_reward = ((num_generations - rank) / (num_generations - 1)) - 0.5\n",
        "\n",
        "    magnitude_reward = 0.0\n",
        "    if time_baseline > 0 and time_baseline != float('inf'):\n",
        "        if time_execution == float('inf'):\n",
        "            magnitude_reward = -0.5\n",
        "        else:\n",
        "            relative_improvement = (time_baseline - time_execution) / time_baseline\n",
        "            magnitude_reward = np.tanh(relative_improvement) * 0.5\n",
        "\n",
        "    hybrid_reward = beta * rank_reward + (1 - beta) * magnitude_reward\n",
        "\n",
        "    return hybrid_reward\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZjDMF5NrNGdo"
      },
      "outputs": [],
      "source": [
        "def split_dataset(dataset, test_size=0.1, seed=42):\n",
        "    return dataset.train_test_split(test_size=test_size, seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ZLazFurXqofH"
      },
      "outputs": [],
      "source": [
        "def main(json_file: str, sft_model_path: str, output_dir: str):\n",
        "\n",
        "    print(\"GSPO Training\")\n",
        "\n",
        "    print(\"\\n[1/6] загрузка модели\")\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_8bit=True,\n",
        "        bnb_8bit_compute_dtype=torch.float16,\n",
        "        bnb_8bit_use_double_quant=True\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        sft_model_path,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map='auto',\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        sft_model_path,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "\n",
        "    with open(\"chat_template.jinja\", \"r\", encoding=\"utf-8\") as f:\n",
        "        chat_template = f.read()\n",
        "    tokenizer.chat_template = chat_template\n",
        "    tokenizer.padding_side = 'left'\n",
        "\n",
        "    print(tokenizer.chat_template)\n",
        "\n",
        "    print(\"\\n[2/6] загрузка датасета\")\n",
        "\n",
        "    raw_dataset = prepare_grpo_dataset(json_file, tokenizer)\n",
        "    print(f\"загружено {len(raw_dataset)} примеров\")\n",
        "\n",
        "    print(\"\\n[3/6] LoRA\")\n",
        "\n",
        "    lora_config = LoraConfig(\n",
        "        r=16,\n",
        "        lora_alpha=32,\n",
        "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                       \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\"\n",
        "    )\n",
        "\n",
        "    model = get_peft_model(model, lora_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    print(\"\\n[4/6] train val для GRPO\")\n",
        "\n",
        "    train_val = split_dataset(raw_dataset)\n",
        "    train_dataset, val_dataset = train_val['train'], train_val['test']\n",
        "\n",
        "    print(f\"train: {len(train_dataset)}, val: {len(val_dataset)}\")\n",
        "    print(f\"колонки: {train_dataset.column_names}\")\n",
        "\n",
        "    print(\"\\n[5/6] конфиг GRPO\")\n",
        "\n",
        "    training_args = GRPOConfig(\n",
        "        output_dir=output_dir,\n",
        "\n",
        "        num_train_epochs=1,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        gradient_accumulation_steps=4,\n",
        "        learning_rate=5e-6,\n",
        "\n",
        "        num_generations=4,\n",
        "        max_completion_length=150,\n",
        "        max_prompt_length=3000,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        top_k=20,\n",
        "        #scale_rewards=\"group\",\n",
        "        #loss_type=\"dapo\",\n",
        "        beta=0.0,\n",
        "        importance_sampling_level=\"sequence\",\n",
        "\n",
        "        max_grad_norm=1.0,\n",
        "        warmup_steps=20,\n",
        "\n",
        "        logging_steps=1,\n",
        "        save_steps=5,\n",
        "        eval_steps=5,\n",
        "        save_total_limit=5,\n",
        "\n",
        "        eval_strategy=\"steps\",\n",
        "\n",
        "        bf16=False,\n",
        "        fp16=True,\n",
        "        gradient_checkpointing=True,\n",
        "        remove_unused_columns=False,\n",
        "\n",
        "        use_vllm=True,\n",
        "        vllm_mode=\"colocate\",\n",
        "        vllm_gpu_memory_utilization=0.6,\n",
        "        vllm_tensor_parallel_size=1,\n",
        "        vllm_guided_decoding_grammar=grammar,\n",
        "\n",
        "\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "\n",
        "    print(f\"Num generations: {training_args.num_generations}\")\n",
        "    print(f\"Train batch size: {training_args.per_device_train_batch_size}\")\n",
        "    print(f\"Max prompt length: {training_args.max_prompt_length}\")\n",
        "    print(f\"Max completion length: {training_args.max_completion_length}\")\n",
        "\n",
        "    print(\"\\n[6/6] запуск обучения\")\n",
        "\n",
        "    trainer = GRPOTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        processing_class=tokenizer,\n",
        "        reward_funcs=reward_func,\n",
        "        callbacks=[ConsoleLoggingCallback()]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    print(\"сохранение модели\")\n",
        "\n",
        "    final_model_path = os.path.join(output_dir, \"final-gspo-model2\")\n",
        "    trainer.save_model(final_model_path)\n",
        "    tokenizer.save_pretrained(final_model_path)\n",
        "\n",
        "    print(f\"модель сохранена: {final_model_path}\")\n",
        "\n",
        "    return trainer, final_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rPZ7hE9_vref",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "outputId": "078cfcc7-6e15-4b9d-da8c-5f87c09b6d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "GSPO Training\n",
            "\n",
            "[1/6] загрузка модели\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-138118583.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mOUTPUT_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/sql_models/gspo-model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJSON_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSFT_MODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3738044340.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(json_file, sft_model_path, output_dir)\u001b[0m\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0msft_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnb_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5027\u001b[0m         \u001b[0;31m# Prepare the full device map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5028\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5029\u001b[0;31m             \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_in_fp32_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5031\u001b[0m         \u001b[0;31m# Finalize model weight initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_get_device_map\u001b[0;34m(model, device_map, max_memory, hf_quantizer, dtype, keep_in_fp32_regex)\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m             \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/quantizers/quantizer_bnb_8bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"disk\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_map_without_lm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                     \u001b[0;34m\"Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0;34m\"quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "JSON_FILE = \"output.json\"\n",
        "SFT_MODEL_PATH = \"/content/drive/My Drive/sql_models/final-model_1\"\n",
        "OUTPUT_DIR = \"/content/drive/My Drive/sql_models/gspo-model\"\n",
        "\n",
        "main(JSON_FILE, SFT_MODEL_PATH, OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKHuplOlOROR"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "gspo_model_path = \"/content/drive/My Drive/sql_models/gspo-model/final-gspo-model2\"\n",
        "SFT_MODEL_PATH = \"/content/drive/My Drive/sql_models/final-model_1\"\n",
        "\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    bnb_8bit_compute_dtype=torch.float16,\n",
        "    bnb_8bit_use_double_quant=True\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    gspo_model_path,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto',\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    gspo_model_path,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "with open(\"chat_template.jinja\", \"r\", encoding=\"utf-8\") as f:\n",
        "    chat_template = f.read()\n",
        "tokenizer.chat_template = chat_template\n",
        "tokenizer.padding_side = 'left'\n",
        "print(tokenizer.chat_template)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWQfybQtQiai"
      },
      "outputs": [],
      "source": [
        "def generate_hints(query, statistics, model, tokenizer):\n",
        "\n",
        "    user_prompt = USER_PROMPT_TEMPLATE.format(\n",
        "        query=query,\n",
        "        card_tb=statistics[\"Card_Tb\"],\n",
        "        ndv=format_ndv_stats(statistics[\"NDV\"]),\n",
        "        main_value=format_main_values(statistics[\"Main_Value\"]),\n",
        "        min_max=format_min_max(statistics[\"Min_Max\"])\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT.strip()},\n",
        "        {\"role\": \"user\", \"content\": user_prompt.strip()},\n",
        "    ]\n",
        "\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=3000,\n",
        "        do_sample=True,\n",
        "        temperature=0.2,\n",
        "        top_p=0.9,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tGlVXRqQwm5"
      },
      "outputs": [],
      "source": [
        "#29a.sql\n",
        "test_statistics = {\"Card_Tb\": \"k : 1 (236627)\\nit : 1 (113)\\nit : 1 (113)\\nt : 11 (3299359)\\ncc : 2 (135086)\\nmi : 1 (29881566)\\nci : 1 (63525648)\\nn : 1 (6379436)\\nchn : 1 (4314624)\\ncct1 : 1 (4)\\nrt : 1 (12)\\npi : 36 (4135549)\\nan : 2 (1312273)\\nmk : 64 (7480081)\\ncct1 : 1 (4)\\nmc : 6 (4958465)\\ncn : 1 (362131)\",\n",
        "    \"NDV\": \"aka_name.md5sum : -0.42351857\\naka_name.name_pcode_cf : 12213.0\\naka_name.imdb_index : -3.3318996e-05\\naka_name.id : -1.0\\naka_name.person_id : -0.40863448\\naka_name.name_pcode_nf : 10619.0\\naka_name.name : -0.42351857\\naka_name.surname_pcode : 2575.0\\ncomplete_cast.movie_id : -0.62968034\\ncomplete_cast.id : -1.0\\ncomplete_cast.status_id : 2.0\\ncomplete_cast.subject_id : 2.0\\ncomp_cast_type.id : -1.0\\ncomp_cast_type.kind : -1.0\\ncomp_cast_type.id : -1.0\\ncomp_cast_type.kind : -1.0\\nchar_name.name_pcode_nf : 12349.0\\nchar_name.id : -1.0\\nchar_name.name : -1.0\\nchar_name.imdb_index : 0.0\\nchar_name.imdb_id : 0.0\\nchar_name.md5sum : -1.0\\nchar_name.surname_pcode : 4931.0\\ncast_info.person_id : 66808.0\\ncast_info.movie_id : 1733126.0\\ncast_info.note : 4054.0\\ncast_info.person_role_id : 20048.0\\ncast_info.id : -1.0\\ncast_info.nr_order : 147.0\\ncast_info.role_id : 11.0\\ncompany_name.country_code : 174.0\\ncompany_name.name_pcode_sf : 11103.0\\ncompany_name.md5sum : -1.0\\ncompany_name.name : -0.86129606\\ncompany_name.id : -1.0\\ncompany_name.imdb_id : 0.0\\ncompany_name.name_pcode_nf : 11853.0\\ninfo_type.info : -1.0\\ninfo_type.id : -1.0\\ninfo_type.info : -1.0\\ninfo_type.id : -1.0\\nkeyword.phonetic_code : 10374.0\\nkeyword.keyword : -1.0\\nkeyword.id : -1.0\\nmovie_companies.company_id : 20568.0\\nmovie_companies.note : 6522.0\\nmovie_companies.movie_id : -0.16302344\\nmovie_companies.id : -1.0\\nmovie_companies.company_type_id : 2.0\\nmovie_info.id : -1.0\\nmovie_info.note : 2190.0\\nmovie_info.info : 24949.0\\nmovie_info.info_type_id : 75.0\\nmovie_info.movie_id : 549133.0\\nmovie_keyword.keyword_id : 18044.0\\nmovie_keyword.id : -1.0\\nmovie_keyword.movie_id : 116740.0\\nname.name_pcode_nf : 10820.0\\nname.surname_pcode : 2644.0\\nname.name : -0.29187077\\nname.imdb_id : 0.0\\nname.gender : 2.0\\nname.name_pcode_cf : 12306.0\\nname.id : -1.0\\nname.md5sum : -1.0\\nname.imdb_index : 110.0\\nperson_info.id : -1.0\\nperson_info.person_id : 113614.0\\nperson_info.info_type_id : 21.0\\nperson_info.info : 160562.0\\nperson_info.note : 4985.0\\nrole_type.id : -1.0\\nrole_type.role : -1.0\\ntitle.imdb_index : -0.000100016594\\ntitle.kind_id : 6.0\\ntitle.imdb_id : 0.0\\ntitle.id : -1.0\\ntitle.episode_nr : 2045.0\\ntitle.title : 78983.0\\ntitle.episode_of_id : 21104.0\\ntitle.series_years : 286.0\\ntitle.md5sum : -1.0\\ntitle.phonetic_code : 10765.0\\ntitle.season_nr : 80.0\\ntitle.production_year : 116.0\",\n",
        "    \"Main_Value\": \"aka_name.md5sum : ['1b83d5da74032b6a750ef12210642eea', 525]\\naka_name.name_pcode_cf : ['J5252', 3937]\\naka_name.name_pcode_nf : ['A4253', 6080]\\naka_name.name : ['Mike', 525]\\naka_name.surname_pcode : ['R2', 8136]\\ncomplete_cast.status_id : ['3', 110626]\\ncomplete_cast.subject_id : ['1', 86320]\\nchar_name.name_pcode_nf : ['H5241', 148135]\\nchar_name.surname_pcode : ['M5', 32935]\\ncast_info.person_id : ['186155', 29645]\\ncast_info.note : ['(producer)', 2530438]\\ncast_info.person_role_id : ['2', 2214928]\\ncast_info.nr_order : ['1', 2094229]\\ncast_info.role_id : ['1', 20495491]\\ncompany_name.country_code : ['[us]', 138250]\\ncompany_name.name_pcode_sf : ['P6325', 1171]\\ncompany_name.name : ['Sony Pictures Releasing', 97]\\ncompany_name.name_pcode_nf : ['P6325', 1243]\\nkeyword.phonetic_code : ['R1652', 25201]\\nmovie_companies.company_id : ['67', 72559]\\nmovie_companies.note : ['(in association with)', 39172]\\nmovie_companies.company_type_id : ['2', 2915743]\\nmovie_info.note : ['Anonymous', 131479]\\nmovie_info.info : ['Color', 1729147]\\nmovie_info.info_type_id : ['16', 5471315]\\nmovie_keyword.keyword_id : ['1078', 81284]\\nmovie_keyword.movie_id : ['3361480', 1995]\\nname.name_pcode_nf : ['A5362', 36150]\\nname.surname_pcode : ['R2', 49547]\\nname.gender : ['m', 2682340]\\nname.name_pcode_cf : ['J5252', 19138]\\nname.imdb_index : ['I', 502487]\\nperson_info.person_id : ['2425605', 2343]\\nperson_info.info_type_id : ['17', 882940]\\nperson_info.info : ['Los Angeles', 15439]\\nperson_info.note : ['Anonymous', 14474]\\ntitle.kind_id : ['7', 3022103]\\ntitle.episode_nr : ['1', 142752]\\ntitle.title : ['(#1.1)', 27495]\\ntitle.episode_of_id : ['628404', 11988]\\ntitle.series_years : ['2015-????', 9128]\\ntitle.phonetic_code : ['A1416', 8248]\\ntitle.season_nr : ['1', 1344269]\\ntitle.production_year : ['2015', 191363]\",\n",
        "    \"Min_Max\": \"aka_name.id : [1, 1312273]\\naka_name.person_id : [5, 6379735]\\ncomplete_cast.id : [1, 135086]\\ncomplete_cast.movie_id : [1781, 4736782]\\ncomplete_cast.subject_id : [1, 2]\\ncomplete_cast.status_id : [3, 4]\\ncomp_cast_type.id : [1, 4]\\ncomp_cast_type.id : [1, 4]\\nchar_name.id : [1, 4314864]\\ncast_info.id : [1, 63475835]\\ncast_info.person_id : [1, 6226526]\\ncast_info.movie_id : [1, 4730370]\\ncast_info.person_role_id : [1, 4314864]\\ncast_info.nr_order : [-2068070866, 1776839230]\\ncast_info.role_id : [1, 11]\\ncompany_name.id : [1, 362131]\\ninfo_type.id : [1, 113]\\ninfo_type.id : [1, 113]\\nkeyword.id : [1, 236627]\\nmovie_companies.id : [1, 4958296]\\nmovie_companies.movie_id : [2, 4698791]\\nmovie_companies.company_id : [1, 362131]\\nmovie_companies.company_type_id : [1, 2]\\nmovie_info.id : [1, 29774686]\\nmovie_info.movie_id : [1, 4730846]\\nmovie_info.info_type_id : [1, 113]\\nmovie_keyword.id : [1, 7480087]\\nmovie_keyword.movie_id : [2, 4730753]\\nmovie_keyword.keyword_id : [1, 236627]\\nname.id : [1, 6379740]\\nperson_info.id : [1, 4130207]\\nperson_info.person_id : [1, 6379740]\\nperson_info.info_type_id : [15, 39]\\nrole_type.id : [1, 12]\\ntitle.id : [100000, 3399999]\\ntitle.kind_id : [1, 8]\\ntitle.production_year : [1888, 2115]\\ntitle.episode_of_id : [99685, 3300011]\\ntitle.season_nr : [1, 2015]\\ntitle.episode_nr : [1, 91334]\"}\n",
        "\n",
        "sql = \"SELECT MIN(chn.name) AS voiced_char,\\n       MIN(n.name) AS voicing_actress,\\n       MIN(t.title) AS voiced_animation\\nFROM aka_name AS an,\\n     complete_cast AS cc,\\n     comp_cast_type AS cct1,\\n     comp_cast_type AS cct2,\\n     char_name AS chn,\\n     cast_info AS ci,\\n     company_name AS cn,\\n     info_type AS it,\\n     info_type AS it3,\\n     keyword AS k,\\n     movie_companies AS mc,\\n     movie_info AS mi,\\n     movie_keyword AS mk,\\n     name AS n,\\n     person_info AS pi,\\n     role_type AS rt,\\n     title AS t\\nWHERE cct1.kind ='cast'\\n  AND cct2.kind ='complete+verified'\\n  AND chn.name = 'Queen'\\n  AND ci.note IN ('(voice)',\\n                  '(voice) (uncredited)',\\n                  '(voice: English version)')\\n  AND cn.country_code ='[us]'\\n  AND it.info = 'release dates'\\n  AND it3.info = 'trivia'\\n  AND k.keyword = 'computer-animation'\\n  AND mi.info IS NOT NULL\\n  AND (mi.info LIKE 'Japan:%200%'\\n       OR mi.info LIKE 'USA:%200%')\\n  AND n.gender ='f'\\n  AND n.name LIKE '%An%'\\n  AND rt.role ='actress'\\n  AND t.title = 'Shrek 2'\\n  AND t.production_year BETWEEN 2000 AND 2010\\n  AND t.id = mi.movie_id\\n  AND t.id = mc.movie_id\\n  AND t.id = ci.movie_id\\n  AND t.id = mk.movie_id\\n  AND t.id = cc.movie_id\\n  AND mc.movie_id = ci.movie_id\\n  AND mc.movie_id = mi.movie_id\\n  AND mc.movie_id = mk.movie_id\\n  AND mc.movie_id = cc.movie_id\\n  AND mi.movie_id = ci.movie_id\\n  AND mi.movie_id = mk.movie_id\\n  AND mi.movie_id = cc.movie_id\\n  AND ci.movie_id = mk.movie_id\\n  AND ci.movie_id = cc.movie_id\\n  AND mk.movie_id = cc.movie_id\\n  AND cn.id = mc.company_id\\n  AND it.id = mi.info_type_id\\n  AND n.id = ci.person_id\\n  AND rt.id = ci.role_id\\n  AND n.id = an.person_id\\n  AND ci.person_id = an.person_id\\n  AND chn.id = ci.person_role_id\\n  AND n.id = pi.person_id\\n  AND ci.person_id = pi.person_id\\n  AND it3.id = pi.info_type_id\\n  AND k.id = mk.keyword_id\\n  AND cct1.id = cc.subject_id\\n  AND cct2.id = cc.status_id;\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHotDWk5BcI2"
      },
      "outputs": [],
      "source": [
        "print(extract_hints_from_completion(generate_hints(sql, test_statistics, model, tokenizer)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}